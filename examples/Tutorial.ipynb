{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW TO USE OPTICHILL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING THE NECESSARY MODULES TO RUN THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# code to add to import from optichill folder\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from optichill import bas_filter\n",
    "from optichill import GBM_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILTERING OUT THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First split the data from Plant 1 to training and testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    'Plt1 m 2018-01.csv', 'Plt1 m 2018-02.csv', 'Plt1 m 2018-03.csv', \n",
    "    'Plt1 m 2018-04.csv' \n",
    "]\n",
    "test_data = [ \n",
    "    'Plt1 m 2016-11.csv', 'Plt1 m 2016-12.csv', 'Plt1 m 2017-01.csv', 'Plt1 m 2017-02.csv',\n",
    "    'Plt1 m 2017-03.csv',\n",
    "    'Plt1 m 2017-04.csv', 'Plt1 m 2017-05.csv', 'Plt1 m 2017-06.csv', 'Plt1 m 2017-07.csv', \n",
    "    'Plt1 m 2017-08.csv', 'Plt1 m 2017-09.csv', 'Plt1 m 2017-10.csv', 'Plt1 m 2017-11.csv', \n",
    "    'Plt1 m 2017-12.csv'\n",
    "]\n",
    "\n",
    "points_list = '../../Plt1/Plt1 Points List.xlsx'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two filtered datasets (training and testing) are obtained using the `train_single_plant` function: \n",
    "`include_alarms` allows you to decide whether you need to include alarms or not, and `dim_remove` allows you to specify which features you want to include or exclude from the dataset. This allows you to explore the fit with certain feature only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `bas_filter.train_single_plant` to allow the data to import the data, filter out features that are redundent and alarms to provide a training and testing dataset that can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering Training Set\n",
      "['../../Plt1\\\\Plt1 m 2018-01.csv']\n",
      "['../../Plt1\\\\Plt1 m 2018-02.csv']\n",
      "['../../Plt1\\\\Plt1 m 2018-03.csv']\n",
      "['../../Plt1\\\\Plt1 m 2018-04.csv']\n",
      "Descriptors in the points list that are not in the datasets.\n",
      "CommunicationFailure_COV\n",
      "CH3COM1F\n",
      "CH3Ready\n",
      "CH4COM1F\n",
      "CH4Ready\n",
      "CH4SURGE\n",
      "CH5COM1F\n",
      "CH5Ready\n",
      "Original data contains 32796 points and 414 dimensions.\n",
      "A CDWP3SPD_Alarm was noted and 8474 datapoints were removed from the dataset.\n",
      "A CDWP4Failed was noted and 8474 datapoints were removed from the dataset.\n",
      "A CDWP4SPD_Alarm was noted and 9993 datapoints were removed from the dataset.\n",
      "A CDWP5Failed was noted and 9993 datapoints were removed from the dataset.\n",
      "A CDWP5SPD_Alarm was noted and 17008 datapoints were removed from the dataset.\n",
      "A CH3_CHWSTSP_Alarm was noted and 17008 datapoints were removed from the dataset.\n",
      "A CH3ALARM was noted and 17008 datapoints were removed from the dataset.\n",
      "A CH3F was noted and 17008 datapoints were removed from the dataset.\n",
      "A CH4_CHWSTSP_Alarm was noted and 17008 datapoints were removed from the dataset.\n",
      "A CH4ALARM was noted and 17012 datapoints were removed from the dataset.\n",
      "A CH4F was noted and 17012 datapoints were removed from the dataset.\n",
      "A CH5_CHWSTSP_Alarm was noted and 17012 datapoints were removed from the dataset.\n",
      "A CH5ALARM was noted and 17142 datapoints were removed from the dataset.\n",
      "A CH5F was noted and 17142 datapoints were removed from the dataset.\n",
      "A CommunicationFailure was noted and 17142 datapoints were removed from the dataset.\n",
      "A CT4Failed was noted and 17142 datapoints were removed from the dataset.\n",
      "A CT4SPD_Alarm was noted and 17157 datapoints were removed from the dataset.\n",
      "A CT5Failed was noted and 17157 datapoints were removed from the dataset.\n",
      "A CT5SPD_Alarm was noted and 17157 datapoints were removed from the dataset.\n",
      "A CTTR_ALARM was noted and 17279 datapoints were removed from the dataset.\n",
      "A PCHWP3Failed was noted and 17279 datapoints were removed from the dataset.\n",
      "A PCHWP4Failed was noted and 17279 datapoints were removed from the dataset.\n",
      "A PCHWP5Failed was noted and 17279 datapoints were removed from the dataset.\n",
      "A SCHWP3Failed was noted and 17279 datapoints were removed from the dataset.\n",
      "A SCHWP4Failed was noted and 17279 datapoints were removed from the dataset.\n",
      "A SCHWP5Failed was noted and 17279 datapoints were removed from the dataset.\n",
      "Filtered data contains 15021 points and 193 dimensions.\n",
      "Filtering Test Set\n",
      "['../../Plt1\\\\Plt1 m 2016-11.csv']\n",
      "['../../Plt1\\\\Plt1 m 2016-12.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-01.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-02.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-03.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-04.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-05.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-06.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-07.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-08.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-09.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-10.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-11.csv']\n",
      "['../../Plt1\\\\Plt1 m 2017-12.csv']\n",
      "Descriptors in the points list that are not in the datasets.\n",
      "CommunicationFailure_COV\n",
      "CH3COM1F\n",
      "CH3Ready\n",
      "CH4COM1F\n",
      "CH4Ready\n",
      "CH4SURGE\n",
      "CH5COM1F\n",
      "CH5Ready\n",
      "Original data contains 114768 points and 414 dimensions.\n",
      "A CDWP3SPD_Alarm was noted and 14718 datapoints were removed from the dataset.\n",
      "A CDWP4Failed was noted and 14718 datapoints were removed from the dataset.\n",
      "A CDWP4SPD_Alarm was noted and 28846 datapoints were removed from the dataset.\n",
      "A CDWP5Failed was noted and 28846 datapoints were removed from the dataset.\n",
      "A CDWP5SPD_Alarm was noted and 65137 datapoints were removed from the dataset.\n",
      "A CH3_CHWSTSP_Alarm was noted and 65137 datapoints were removed from the dataset.\n",
      "A CH3ALARM was noted and 65382 datapoints were removed from the dataset.\n",
      "A CH3F was noted and 65382 datapoints were removed from the dataset.\n",
      "A CH4_CHWSTSP_Alarm was noted and 65382 datapoints were removed from the dataset.\n",
      "A CH4ALARM was noted and 65420 datapoints were removed from the dataset.\n",
      "A CH4F was noted and 69216 datapoints were removed from the dataset.\n",
      "A CH5_CHWSTSP_Alarm was noted and 69216 datapoints were removed from the dataset.\n",
      "A CH5ALARM was noted and 69216 datapoints were removed from the dataset.\n",
      "A CH5F was noted and 69216 datapoints were removed from the dataset.\n",
      "A CommunicationFailure was noted and 69216 datapoints were removed from the dataset.\n",
      "A CT4Failed was noted and 69216 datapoints were removed from the dataset.\n",
      "A CT4SPD_Alarm was noted and 69216 datapoints were removed from the dataset.\n",
      "A CT5Failed was noted and 69216 datapoints were removed from the dataset.\n",
      "A CT5SPD_Alarm was noted and 69219 datapoints were removed from the dataset.\n",
      "A CTTR_ALARM was noted and 69611 datapoints were removed from the dataset.\n",
      "A PCHWP3Failed was noted and 70403 datapoints were removed from the dataset.\n",
      "A PCHWP4Failed was noted and 70403 datapoints were removed from the dataset.\n",
      "A PCHWP5Failed was noted and 70403 datapoints were removed from the dataset.\n",
      "A SCHWP3Failed was noted and 70403 datapoints were removed from the dataset.\n",
      "A SCHWP4Failed was noted and 70403 datapoints were removed from the dataset.\n",
      "A SCHWP5Failed was noted and 70403 datapoints were removed from the dataset.\n",
      "Filtered data contains 37404 points and 193 dimensions.\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = bas_filter.train_single_plt(\n",
    "    '../../Plt1', train_data, test_data, points_list, \n",
    "    include_alarms = False, dim_remove = []\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the data into a datasest with kW/Ton and all the other features. This is similar to splitting the data into \"x and y\"\n",
    "axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = df_train['kW/Ton']\n",
    "ytest = df_test['kW/Ton']\n",
    "xtrain = df_train.drop(['kW/Ton'], axis=1)\n",
    "xtest = df_test.drop(['kW/Ton'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING GBM (GRADIENT BOOSTING MACHINES) FOR DETERMINING FEATURE IMPORTANCE AND PREDICTING EFFICIENCY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the model by using the `GBM_model.train_model` function. The R<sup>2</sup> gets printed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8173298324868562"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM_model.train_model(xtrain, ytrain, xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=6, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=500, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM_model.predict_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save the features importance list (A list of all the features of the plant in order of their importance to the efficiency) into a .csv file using `GBM_model.feature_importance_list`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature importance list was created as Plt1_tutorial.csv\n"
     ]
    }
   ],
   "source": [
    "GBM_model.feature_importance_list('Plt1_tutorial.csv', xtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
